{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DivvyBikeDataLinearPolynomialRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Predicts the volume of bikes needed on various days in May 2021. Uses this dataset: https://www.kaggle.com/datasets/farjadanalytica/divvytripdata-1?select=202105-divvy-tripdata.csv "
      ],
      "metadata": {
        "id": "gdGZv0S2Vfgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "if Path('Data').is_dir():\n",
        "  shutil.rmtree('Data')"
      ],
      "metadata": {
        "id": "iNKCUDNo71NW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sd0nQpJxRtib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bdabed-4fcf-4ea8-baee-c065f0d90b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Data.zip\n",
            "  inflating: Data/202005-divvy-tripdata.csv  \n",
            "  inflating: Data/202006-divvy-tripdata.csv  \n",
            "  inflating: Data/202007-divvy-tripdata.csv  \n",
            "  inflating: Data/202008-divvy-tripdata.csv  \n",
            "  inflating: Data/202009-divvy-tripdata.csv  \n",
            "  inflating: Data/202010-divvy-tripdata.csv  \n",
            "  inflating: Data/202011-divvy-tripdata.csv  \n",
            "  inflating: Data/202012-divvy-tripdata.csv  \n",
            "  inflating: Data/202101-divvy-tripdata.csv  \n",
            "  inflating: Data/202102-divvy-tripdata.csv  \n",
            "  inflating: Data/202103-divvy-tripdata.csv  \n",
            "  inflating: Data/202104-divvy-tripdata.csv  \n",
            "  inflating: Data/202105-divvy-tripdata.csv  \n",
            "  inflating: Data/all-months-divvy-tripdata.csv  \n",
            "  inflating: Data/chicago_daily_weather_data.csv  \n",
            "  inflating: Data/chicago_hourly_weather_data.csv  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import urllib.request\n",
        "import csv\n",
        "import codecs\n",
        "from scipy import stats\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "!unzip 'Data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_divvy = pd.read_csv('Data/all-months-divvy-tripdata.csv', on_bad_lines='skip')\n",
        "#df_divvy[:20]\n",
        "months = ['202005', '202006', '202007', '202008', '202009', '202010', '202011', '202012', '202101', '202102', '202103', '202104', '202105']\n",
        "ride_data_files = ['Data/' + month + '-divvy-tripdata.csv' for month in months]\n",
        "df_divvy = pd.concat((pd.read_csv(f) for f in ride_data_files))\n",
        "print(len(df_divvy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jFREqZBR4iu",
        "outputId": "7744bcea-62f9-40e4-a4ec-1697e109a68f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3391402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get historical weather data\n",
        "weather_df = pd.read_csv('Data/chicago_daily_weather_data.csv')\n",
        "weather_df.loc[weather_df['datetime'] == '2020-05-01']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "f99Al3KM6sXH",
        "outputId": "686838f7-91b8-4edd-a9b7-f4c83541eb51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                name    datetime  tempmax  tempmin  temp  feelslikemax  \\\n",
              "0  chicago, illinois  2020-05-01     66.6     38.6  53.6          66.6   \n",
              "\n",
              "   feelslikemin  feelslike   dew  humidity  ...  solarenergy  uvindex  \\\n",
              "0          38.6       53.4  35.6      54.7  ...         22.7        9   \n",
              "\n",
              "   severerisk              sunrise               sunset  moonphase  \\\n",
              "0         NaN  2020-05-01T05:46:00  2020-05-01T19:49:49       0.28   \n",
              "\n",
              "         conditions                        description               icon  \\\n",
              "0  Partially cloudy  Partly cloudy throughout the day.  partly-cloudy-day   \n",
              "\n",
              "                                            stations  \n",
              "0  72534014819,KORD,KMDW,72530094846,74466504838,...  \n",
              "\n",
              "[1 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cae822bc-43de-4f3f-ab08-c34e78096383\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>tempmax</th>\n",
              "      <th>tempmin</th>\n",
              "      <th>temp</th>\n",
              "      <th>feelslikemax</th>\n",
              "      <th>feelslikemin</th>\n",
              "      <th>feelslike</th>\n",
              "      <th>dew</th>\n",
              "      <th>humidity</th>\n",
              "      <th>...</th>\n",
              "      <th>solarenergy</th>\n",
              "      <th>uvindex</th>\n",
              "      <th>severerisk</th>\n",
              "      <th>sunrise</th>\n",
              "      <th>sunset</th>\n",
              "      <th>moonphase</th>\n",
              "      <th>conditions</th>\n",
              "      <th>description</th>\n",
              "      <th>icon</th>\n",
              "      <th>stations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chicago, illinois</td>\n",
              "      <td>2020-05-01</td>\n",
              "      <td>66.6</td>\n",
              "      <td>38.6</td>\n",
              "      <td>53.6</td>\n",
              "      <td>66.6</td>\n",
              "      <td>38.6</td>\n",
              "      <td>53.4</td>\n",
              "      <td>35.6</td>\n",
              "      <td>54.7</td>\n",
              "      <td>...</td>\n",
              "      <td>22.7</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-05-01T05:46:00</td>\n",
              "      <td>2020-05-01T19:49:49</td>\n",
              "      <td>0.28</td>\n",
              "      <td>Partially cloudy</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "      <td>partly-cloudy-day</td>\n",
              "      <td>72534014819,KORD,KMDW,72530094846,74466504838,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cae822bc-43de-4f3f-ab08-c34e78096383')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cae822bc-43de-4f3f-ab08-c34e78096383 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cae822bc-43de-4f3f-ab08-c34e78096383');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge weather data and Divvy dataset\n",
        "df_divvy['datetime'] = df_divvy.apply(lambda x : x['started_at'].split(' ')[0], axis=1)\n",
        "df_divvy['datetime'] = df_divvy['datetime'].apply(lambda x : x.split('/')[2] + '-' + ('0' + x.split('/')[0])[-2:] + '-' + ('0' + x.split('/')[1])[-2:])\n",
        "print(df_divvy.head())\n",
        "#df_divvy['temperature'] = df_divvy.apply(lambda x : weather_df.loc[weather_df['datetime'] == x['started_at']]['temp'], axis=1)\n",
        "#df_divvy_weather = pd.merge(df_divvy, weather_df, on='datetime')\n",
        "#df_divvy.merge(weather_df, on='datetime', how='left')\n",
        "df_divvy_weather = pd.merge(df_divvy, weather_df, on='datetime', how='left')\n",
        "df_divvy_weather[['started_at', 'datetime', 'temp', 'precip', 'windspeed']].iloc[[1,3000,5000,7000,10000,15000,20000]]\n",
        "print(len(df_divvy))\n",
        "print(len(df_divvy_weather))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dnMTzh9FvaT",
        "outputId": "23bbdadf-a3fe-45cb-915b-1ce70f134f3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ride_id rideable_type       started_at         ended_at  \\\n",
            "0  93708F49670AE324   docked_bike    5/7/2020 1:18   5/27/2020 2:55   \n",
            "1  305C4EFEBE542DA7   docked_bike  5/15/2020 15:12  5/26/2020 16:40   \n",
            "2  0C666D8148BD3A6F   docked_bike    5/1/2020 7:48   5/12/2020 7:49   \n",
            "3  6BFE0820278C6D56   docked_bike  5/19/2020 12:29  5/29/2020 13:05   \n",
            "4  4323B2931BF64CA3   docked_bike  5/13/2020 16:50  5/23/2020 17:12   \n",
            "\n",
            "            start_station_name start_station_id            end_station_name  \\\n",
            "0  Spaulding Ave & Division St              510     Karlov Ave & Madison St   \n",
            "1      MLK Jr Dr & Pershing Rd              179      St. Clair St & Erie St   \n",
            "2               DuSable Museum              422    Commercial Ave & 83rd St   \n",
            "3      Lincoln Ave & Winona St              472     Lincoln Ave & Winona St   \n",
            "4     Southport Ave & Clark St              292  Clarendon Ave & Leland Ave   \n",
            "\n",
            "  end_station_id  start_lat  start_lng  end_lat  end_lng member_casual  \\\n",
            "0            534    41.9027   -87.7092  41.8809 -87.7279        casual   \n",
            "1            211    41.8246   -87.6168  41.8944 -87.6227        casual   \n",
            "2            581    41.7916   -87.6079  41.7446 -87.5512        casual   \n",
            "3            472    41.9749   -87.6925  41.9749 -87.6925        casual   \n",
            "4            251    41.9571   -87.6642  41.9680 -87.6500        casual   \n",
            "\n",
            "   Unnamed: 13   s    datetime  \n",
            "0          NaN NaN  2020-05-07  \n",
            "1          NaN NaN  2020-05-15  \n",
            "2          NaN NaN  2020-05-01  \n",
            "3          NaN NaN  2020-05-19  \n",
            "4          NaN NaN  2020-05-13  \n",
            "3391402\n",
            "3391402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: ride and weather data. Output: features for which p value for chi2 is less than 0.05\n",
        "def chi2_test(df):\n",
        "  ridership_cutoff = 1000 # less than this is fewer rides, more than this is more rides\n",
        "  features_cutoffs = {'weekend_or_holiday': '>0.01', 'temp': '>50', 'precip': '<0.01', 'windspeed': '<20', 'snowdepth': '<0.01', 'humidity': '<65', 'feelslike': '>50'} # key: feature, value: rule for distinguishing good weather from bad weather for that feature\n",
        "  influential_features = {} # key: feature, value: p value. Only includes features with p value less than 0.05\n",
        "  ridershiphigh_weathergood, ridershiphigh_weatherbad, ridershiplow_weathergood, ridershiplow_weatherbad = None, None, None, None\n",
        "\n",
        "  for feature in list(features_cutoffs.keys()):\n",
        "    feature_cutoff = float(features_cutoffs[feature][1:])\n",
        "    if features_cutoffs[feature][0] == '>':\n",
        "      ridershiphigh_weathergood = len(df[(df['rides_count']>=ridership_cutoff)&(df[feature]>=feature_cutoff)])\n",
        "      ridershiphigh_weatherbad = len(df[(df['rides_count']>=ridership_cutoff)&(df[feature]<feature_cutoff)])\n",
        "      ridershiplow_weathergood = len(df[(df['rides_count']<ridership_cutoff)&(df[feature]>=feature_cutoff)])\n",
        "      ridershiplow_weatherbad = len(df[(df['rides_count']<ridership_cutoff)&(df[feature]<feature_cutoff)])\n",
        "    elif features_cutoffs[feature][0] == '<':\n",
        "      ridershiphigh_weathergood = len(df[(df['rides_count']>=ridership_cutoff)&(df[feature]<=feature_cutoff)])\n",
        "      ridershiphigh_weatherbad = len(df[(df['rides_count']>=ridership_cutoff)&(df[feature]>feature_cutoff)])\n",
        "      ridershiplow_weathergood = len(df[(df['rides_count']<ridership_cutoff)&(df[feature]<=feature_cutoff)])\n",
        "      ridershiplow_weatherbad = len(df[(df['rides_count']<ridership_cutoff)&(df[feature]>feature_cutoff)])\n",
        "    table = [[ridershiphigh_weathergood, ridershiphigh_weatherbad],[ridershiplow_weathergood, ridershiplow_weatherbad]]\n",
        "    p = stats.chi2_contingency(table)[1]\n",
        "    if p < 0.05:\n",
        "      influential_features[feature] = p\n",
        "  \n",
        "  return influential_features\n",
        "    "
      ],
      "metadata": {
        "id": "sMTL9qU86jDt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find total number of bikes used on each day\n",
        "ride_date_counts = {} # key: ride_date, value: number of rides on that date\n",
        "ride_date_weather = {} # key: ride_date, value: [temp, precip, windspeed, snowdepth, humidity, feelslike]\n",
        "ride_date_weekend_bool = {} # key: ride_date, value: 1 if the date is a Saturday, Sunday, or holiday, else 0\n",
        "holidays = ['2020-01-01', '2020-01-20', '2020-05-25', '2020-07-03', '2020-09-07', '2020-11-11', '2020-11-26', '2020-12-25',\n",
        "            '2021-01-01', '2020-01-18', '2021-05-31', '2021-07-05', '2021-09-06', '2021-11-11', '2021-11-25', '2021-12-24', '2021-12-31']\n",
        "for index, row in df_divvy_weather.iterrows():\n",
        "    if row['datetime'] not in ride_date_counts.keys():\n",
        "      ride_date_counts[row['datetime']] = 1\n",
        "      ride_date_weather[row['datetime']] = [row['temp'], row['precip'], row['windspeed'], row['snowdepth'], row['humidity'], row['feelslike']]\n",
        "      current_timestamp = pd.Timestamp(row['datetime'])\n",
        "      ride_date_weekend_bool[row['datetime']] = int(current_timestamp.dayofweek in [5,6] or row['datetime'] in holidays)\n",
        "    else:\n",
        "      ride_date_counts[row['datetime']] += 1\n",
        "#print(ride_date_counts)\n",
        "#print(ride_date_weather)\n",
        "\n",
        "ride_data = pd.DataFrame()\n",
        "ride_data['datetime'] = list(ride_date_counts.keys())\n",
        "ride_data['rides_count'] = list(ride_date_counts.values())\n",
        "ride_data['weekend_or_holiday'] = list(ride_date_weekend_bool.values())\n",
        "ride_data['temp'] = [weather_data[0] for weather_data in list(ride_date_weather.values())]\n",
        "ride_data['precip'] = [weather_data[1] for weather_data in list(ride_date_weather.values())]\n",
        "ride_data['windspeed'] = [weather_data[2] for weather_data in list(ride_date_weather.values())]\n",
        "ride_data['snowdepth'] = [weather_data[3] for weather_data in list(ride_date_weather.values())]\n",
        "ride_data['humidity'] = [weather_data[4] for weather_data in list(ride_date_weather.values())]\n",
        "ride_data['feelslike'] = [weather_data[5] for weather_data in list(ride_date_weather.values())]\n",
        "#print(ride_data)\n",
        "\n",
        "# Do chi2 test to determine which variables most influence Divvy bike usage\n",
        "significant_features = chi2_test(ride_data)\n",
        "print(significant_features)\n",
        "\n",
        "#x = ride_data[['weekend_or_holiday', 'temp', 'precip', 'windspeed']]\n",
        "#x = ride_data[['weekend_or_holiday', 'humidity', 'temp', 'windspeed']] # Use features that the chi2 test showed were most important\n",
        "x = ride_data[['weekend_or_holiday', 'feelslike', 'humidity']]\n",
        "#x = ride_data[['weekend_or_holiday', 'temp', 'windspeed']]\n",
        "y = ride_data[['rides_count']]\n",
        "#print(ride_data)\n",
        "#print(x)\n",
        "#print(y)\n",
        "#print(list(ride_date_counts.keys()) == list(ride_date_weather.keys()) == list(ride_date_weekend_bool.keys()))\n",
        "\"\"\"\n",
        "plt.figure(figsize=(40, 20))\n",
        "plt.plot(list(start_date_counts.keys()), list(start_date_counts.values()))\n",
        "plt.title('Divvy Bike Usage per Day of May 2021')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Number of Bikes Used')\n",
        "plt.savefig('bike_usage_per_day.png')\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "cJ3s5xCwUj7n",
        "outputId": "a5de6c85-aed2-4c0a-8524-644059a92799"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weekend_or_holiday': 0.015342872964248926, 'temp': 0.0008313071172927805, 'snowdepth': 3.268898539634542e-08, 'humidity': 0.011051053125211851, 'feelslike': 0.0015760777242487035}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.figure(figsize=(40, 20))\\nplt.plot(list(start_date_counts.keys()), list(start_date_counts.values()))\\nplt.title('Divvy Bike Usage per Day of May 2021')\\nplt.xlabel('Day')\\nplt.ylabel('Number of Bikes Used')\\nplt.savefig('bike_usage_per_day.png')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature transformation\n",
        "\n",
        "# PCA\n",
        "\"\"\"\n",
        "pca = PCA(n_components=1)\n",
        "x = pca.fit_transform(x)\n",
        "\"\"\"\n",
        "# Scaling\n",
        "scaling_type = 'standard'\n",
        "if scaling_type == 'standard':\n",
        "  scaler = StandardScaler()\n",
        "elif scaling_type == 'minmax':\n",
        "  scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2I8bvlG5WXH",
        "outputId": "6c1a5bec-a186-42ee-adb2-f48a07265384"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.66972338  0.11881302 -1.25076601]\n",
            " [-0.66972338  0.69905906  1.2543753 ]\n",
            " [-0.66972338  0.11881302 -0.63894932]\n",
            " ...\n",
            " [-0.66972338  0.68160805  0.75003992]\n",
            " [-0.66972338 -0.00334404 -1.78817257]\n",
            " [ 1.49315378  0.32822512 -0.80430518]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test linear regression model\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "coef = linear_model.coef_\n",
        "intercept = linear_model.intercept_\n",
        "print(linear_model.score(X_test, y_test)) # R^2\n",
        "print(coef)\n",
        "print(intercept)\n",
        "print(len(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHwS_2tG-x3",
        "outputId": "1a4c39cc-876e-41a3-8533-0dac2b87428b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5477511849017458\n",
            "[[ 1266.45487247  4689.49466841 -1174.69183663]]\n",
            "[8679.33243279]\n",
            "394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plot showing regression line\n",
        "\"\"\"\n",
        "print(len(np.arange(1,364)))\n",
        "print(np.sort(y).shape)\n",
        "#print(np.sort(y, axis=0))\n",
        "plt.plot(np.arange(1,364), np.sort(y, axis=0), 'o', label='original data')\n",
        "y_plot = np.sort(intercept[0] + coef[0][0]*x['weekend_or_holiday'] + coef[0][1]*x['humidity'] + coef[0][2]*x['temp'] + coef[0][3]*x['windspeed'])\n",
        "plt.plot(np.arange(1,364), y_plot, 'r', label='fitted line')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.xlabel('Weekend/Holiday/Temperature Data')\n",
        "plt.ylabel('Number of Bikes Used')\n",
        "plt.title('Linear Regression - Divvy Bike Usage')\n",
        "plt.savefig('lin_reg_divvy_bikes.png')\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "zMWv_SeYHiz-",
        "outputId": "dbbc126c-8415-4e41-da0e-08cddc69efee"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint(len(np.arange(1,364)))\\nprint(np.sort(y).shape)\\n#print(np.sort(y, axis=0))\\nplt.plot(np.arange(1,364), np.sort(y, axis=0), 'o', label='original data')\\ny_plot = np.sort(intercept[0] + coef[0][0]*x['weekend_or_holiday'] + coef[0][1]*x['humidity'] + coef[0][2]*x['temp'] + coef[0][3]*x['windspeed'])\\nplt.plot(np.arange(1,364), y_plot, 'r', label='fitted line')\\nplt.legend()\\n#plt.show()\\nplt.xlabel('Weekend/Holiday/Temperature Data')\\nplt.ylabel('Number of Bikes Used')\\nplt.title('Linear Regression - Divvy Bike Usage')\\nplt.savefig('lin_reg_divvy_bikes.png')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial fit\n",
        "#polynomial_model = np.poly1d(np.polyfit(x, y, 5))\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = poly.fit_transform(X_train) \n",
        "# x0, x1, x2, x3, x0^2, x0x1, \n",
        "# x0x2, x0x3, x1^2,\n",
        "print(X_train[0:4])\n",
        "print(poly_features[0:4])\n",
        "poly_reg_model = LinearRegression()\n",
        "poly_reg_model.fit(poly_features, y_train)\n",
        "coef = poly_reg_model.coef_\n",
        "intercept = poly_reg_model.intercept_\n",
        "X_test_features = poly.fit_transform(X_test)\n",
        "print(poly_reg_model.score(X_test_features, y_test)) # R^2\n",
        "print(coef)\n",
        "print(intercept)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd3ft8Q_Ks1a",
        "outputId": "ae646770-af61-49df-d4fa-29fc6da60e71"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.66972338 -0.3349132   0.27050792]\n",
            " [ 1.49315378  0.95646143 -0.20902408]\n",
            " [ 1.49315378 -1.02859079  1.68430055]\n",
            " [-0.66972338  0.24533283 -1.8708505 ]]\n",
            "[[-0.66972338 -0.3349132   0.27050792  0.44852941  0.2242992  -0.18116548\n",
            "   0.11216685 -0.09059667  0.07317454]\n",
            " [ 1.49315378  0.95646143 -0.20902408  2.2295082   1.428144   -0.31210509\n",
            "   0.91481847 -0.19992347  0.04369107]\n",
            " [ 1.49315378 -1.02859079  1.68430055  2.2295082  -1.53584423  2.51491972\n",
            "   1.05799902 -1.73245603  2.83686833]\n",
            " [-0.66972338  0.24533283 -1.8708505   0.44852941 -0.16430514  1.25295233\n",
            "   0.0601882  -0.45898105  3.50008158]]\n",
            "0.6277623305739235\n",
            "[[-3.61217539e+15  5.19300000e+03 -1.18487500e+03  4.38674043e+15\n",
            "   9.64562500e+02 -3.53437500e+02  9.99375000e+02 -8.20140625e+02\n",
            "  -4.51906250e+02]]\n",
            "[-4.38674043e+15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "cv_results = cross_validate(poly_reg_model, poly_features, y_train, cv=10)\n",
        "print(cv_results)\n",
        "print(np.average(cv_results['fit_time']))\n",
        "print(np.average(cv_results['score_time']))\n",
        "print(np.average(cv_results['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E319rk12Qh0M",
        "outputId": "f7ea60e8-d542-4580-bc1d-610c337524e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.00485706, 0.00312209, 0.00285554, 0.00434542, 0.00214338,\n",
            "       0.00229073, 0.00242543, 0.0024538 , 0.00192881, 0.00196004]), 'score_time': array([0.00338697, 0.0016942 , 0.00237656, 0.00192642, 0.00142241,\n",
            "       0.00154734, 0.00149345, 0.00136828, 0.00140882, 0.00137663]), 'test_score': array([0.51030312, 0.39729334, 0.69418671, 0.7401128 , 0.78271705,\n",
            "       0.54749415, 0.74508956, 0.67565607, 0.54817241, 0.69397312])}\n",
            "0.0028382301330566405\n",
            "0.0018001079559326171\n",
            "0.6334998330679984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "plt.plot(np.arange(1,364), np.sort(y, axis=0), 'o', label='original data')\n",
        "#y_plot = X_test_features * coef + intercept\n",
        "#plt.plot(np.arange(1,364), y_plot)\n",
        "all_features = np.concatenate((poly_features, X_test_features), axis=0)\n",
        "print(all_features.shape)\n",
        "print(coef.shape)\n",
        "plt.plot(np.arange(1,364), sorted(np.matmul(all_features, coef.T) + intercept))\n",
        "plt.xlabel('Weekend/Holiday/Temperature Data')\n",
        "plt.ylabel('Number of Bikes Used')\n",
        "plt.title('Polynomial Regression - Divvy Bike Usage')\n",
        "plt.savefig('polynomial_reg_divvy_bikes.png')\n",
        "\"\"\"\n",
        "#print(r2_score(y, polynomial_model(x)))\n",
        "#print(polynomial_model) # coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "0PQhK5YVO33x",
        "outputId": "fc496a87-7a51-470c-e779-14b9d8201e4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.plot(np.arange(1,364), np.sort(y, axis=0), 'o', label='original data')\\n#y_plot = X_test_features * coef + intercept\\n#plt.plot(np.arange(1,364), y_plot)\\nall_features = np.concatenate((poly_features, X_test_features), axis=0)\\nprint(all_features.shape)\\nprint(coef.shape)\\nplt.plot(np.arange(1,364), sorted(np.matmul(all_features, coef.T) + intercept))\\nplt.xlabel('Weekend/Holiday/Temperature Data')\\nplt.ylabel('Number of Bikes Used')\\nplt.title('Polynomial Regression - Divvy Bike Usage')\\nplt.savefig('polynomial_reg_divvy_bikes.png')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging Ensemble Method\n",
        "\"\"\"\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "linear_regr_bagging = BaggingRegressor(base_estimator=linear_model, n_estimators=4, random_state=0).fit(X_train, y_train)\n",
        "linear_regr_bagging.predict(X_test)\n",
        "print(linear_regr_bagging.score(X_test, y_test))\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "poly_regr_bagging = BaggingRegressor(base_estimator=poly_reg_model, n_estimators=4, random_state=0).fit(poly_features, y_train)\n",
        "poly_regr_bagging.predict(X_test_features)\n",
        "print(poly_regr_bagging.score(X_test_features, y_test))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "96JgIMNIc3F4",
        "outputId": "b545078b-9d58-405b-ffd9-336aeb81119c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.ensemble import BaggingRegressor\\nlinear_regr_bagging = BaggingRegressor(base_estimator=linear_model, n_estimators=4, random_state=0).fit(X_train, y_train)\\nlinear_regr_bagging.predict(X_test)\\nprint(linear_regr_bagging.score(X_test, y_test))\\n\\nfrom sklearn.ensemble import BaggingRegressor\\npoly_regr_bagging = BaggingRegressor(base_estimator=poly_reg_model, n_estimators=4, random_state=0).fit(poly_features, y_train)\\npoly_regr_bagging.predict(X_test_features)\\nprint(poly_regr_bagging.score(X_test_features, y_test))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking\n",
        "\"\"\"\n",
        "from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor\n",
        "estimators = [('linear', linear_model), ('polynomial', poly_reg_model)]\n",
        "reg_stacking = StackingRegressor(estimators=estimators).fit(X_train, y_train)\n",
        "reg_stacking.predict(X_test)\n",
        "print(reg_stacking.score(X_test, y_test))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZwSGW23nFl1p",
        "outputId": "c089a15d-877e-4969-9fd6-551e50d949a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.ensemble import StackingRegressor, GradientBoostingRegressor\\nestimators = [('linear', linear_model), ('polynomial', poly_reg_model)]\\nreg_stacking = StackingRegressor(estimators=estimators).fit(X_train, y_train)\\nreg_stacking.predict(X_test)\\nprint(reg_stacking.score(X_test, y_test))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for bagging and gradient boosting regressor, using both linear and polynomial model\n",
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def regr_grid_search(regr_model, parameters, X_train, y_train, X_test, y_test):\n",
        "  #regr_optimized = BaggingRegressor()\n",
        "  clf = GridSearchCV(regr_model, parameters, scoring='r2', cv=5)\n",
        "  #print(clf.get_params().keys())\n",
        "  clf.fit(X_train, np.ravel(y_train))\n",
        "  print(clf.score(X_test, np.ravel(y_test)))\n",
        "  print(clf.scorer_)\n",
        "  print(clf.best_score_)\n",
        "  #print(clf.cv_results_)\n",
        "  print(clf.best_params_)\n",
        "\n",
        "# Bagging\n",
        "parameters = {'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'max_samples':[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
        "print(\"linear, bagging\")\n",
        "regr_grid_search(linear_regr_bagging, parameters, X_train, y_train, X_test, y_test)\n",
        "print(\"polynomial, bagging\")\n",
        "regr_grid_search(poly_regr_bagging, parameters, poly_features, y_train, X_test_features, y_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "parameters = {'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'subsample':[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
        "print(\"linear, gradient boosting\")\n",
        "regr_grid_search(GradientBoostingRegressor(), parameters, X_train, y_train, X_test, y_test)\n",
        "print(\"polynomial, gradient boosting\")\n",
        "regr_grid_search(GradientBoostingRegressor(), parameters, poly_features, y_train, X_test_features, y_test)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "t5yrTzOze_51",
        "outputId": "14a2e74c-ba68-4e06-a73b-5578fa1bdcb4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import GridSearchCV\\n\\ndef regr_grid_search(regr_model, parameters, X_train, y_train, X_test, y_test):\\n  #regr_optimized = BaggingRegressor()\\n  clf = GridSearchCV(regr_model, parameters, scoring=\\'r2\\', cv=5)\\n  #print(clf.get_params().keys())\\n  clf.fit(X_train, np.ravel(y_train))\\n  print(clf.score(X_test, np.ravel(y_test)))\\n  print(clf.scorer_)\\n  print(clf.best_score_)\\n  #print(clf.cv_results_)\\n  print(clf.best_params_)\\n\\n# Bagging\\nparameters = {\\'n_estimators\\': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \\'max_samples\\':[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\\nprint(\"linear, bagging\")\\nregr_grid_search(linear_regr_bagging, parameters, X_train, y_train, X_test, y_test)\\nprint(\"polynomial, bagging\")\\nregr_grid_search(poly_regr_bagging, parameters, poly_features, y_train, X_test_features, y_test)\\n\\n# Gradient Boosting\\nparameters = {\\'n_estimators\\': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \\'subsample\\':[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\\nprint(\"linear, gradient boosting\")\\nregr_grid_search(GradientBoostingRegressor(), parameters, X_train, y_train, X_test, y_test)\\nprint(\"polynomial, gradient boosting\")\\nregr_grid_search(GradientBoostingRegressor(), parameters, poly_features, y_train, X_test_features, y_test)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Graph results of the best models\n",
        "# Linear Gradient Boosting: max_samples=1.0, n_estimators=17\n",
        "gbr = GradientBoostingRegressor(random_state=0, max_samples=1.0, n_estimators=17)\n",
        "gbr.fit(X_train, y_train)\n",
        "y_pred = gbr.predict(X_test[1:2])\n",
        "print(gbr.score(X_test, y_test))\n",
        "\n",
        "print(np.sort(y_pred).shape)\n",
        "#print(np.sort(y, axis=0))\n",
        "plt.plot(np.arange(1,364), np.sort(y_pred, axis=0), 'o', label='original data')\n",
        "y_plot = np.sort(intercept[0] + coef[0][0]*x['weekend_or_holiday'] + coef[0][1]*x['humidity'] + coef[0][2]*x['temp'] + coef[0][3]*x['windspeed'])\n",
        "plt.plot(np.arange(1,364), y_plot, 'r', label='fitted line')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.xlabel('Weekend/Holiday/Temperature Data')\n",
        "plt.ylabel('Number of Bikes Used')\n",
        "plt.title('Linear Regression - Divvy Bike Usage')\n",
        "plt.savefig('lin_reg_optimized.png')\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "PCtdPeEFr_9B",
        "outputId": "b3ce96b3-64e9-469f-895f-d3c80ed49bdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Graph results of the best models\\n# Linear Gradient Boosting: max_samples=1.0, n_estimators=17\\ngbr = GradientBoostingRegressor(random_state=0, max_samples=1.0, n_estimators=17)\\ngbr.fit(X_train, y_train)\\ny_pred = gbr.predict(X_test[1:2])\\nprint(gbr.score(X_test, y_test))\\n\\nprint(np.sort(y_pred).shape)\\n#print(np.sort(y, axis=0))\\nplt.plot(np.arange(1,364), np.sort(y_pred, axis=0), 'o', label='original data')\\ny_plot = np.sort(intercept[0] + coef[0][0]*x['weekend_or_holiday'] + coef[0][1]*x['humidity'] + coef[0][2]*x['temp'] + coef[0][3]*x['windspeed'])\\nplt.plot(np.arange(1,364), y_plot, 'r', label='fitted line')\\nplt.legend()\\n#plt.show()\\nplt.xlabel('Weekend/Holiday/Temperature Data')\\nplt.ylabel('Number of Bikes Used')\\nplt.title('Linear Regression - Divvy Bike Usage')\\nplt.savefig('lin_reg_optimized.png')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge and Lasso Regression\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "def regression_optimizer(model, parameters, X_train, y_train, X_test, y_test):\n",
        "  clf = GridSearchCV(model, parameters,cv=5)\n",
        "  clf.fit(X_train,y_train)\n",
        "  mean_test_score = clf.cv_results_['mean_test_score']\n",
        "  best_params = clf.best_params_\n",
        "  best_score = clf.best_score_\n",
        "  # Find performance and coefficients for best model\n",
        "  clf = Ridge(alpha=clf.best_params_['alpha'])\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf.predict(X_test)\n",
        "  test_score = clf.score(X_test, y_test)\n",
        "  coef = clf.coef_\n",
        "  intercept = clf.intercept_\n",
        "  print(best_params)\n",
        "  print(best_score)\n",
        "  print(test_score)\n",
        "  print(coef)\n",
        "  print(intercept)\n",
        "  return best_params, best_score, test_score, coef, intercept\n",
        "   \n",
        "\n",
        "print(\"Linear, Ridge\")\n",
        "#parameters = {'alpha':[0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.2, 0.3, 0.5, 0.75, 1.0, 1.5, 2.0, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.05, 3.1, 3.15, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 5.0, 6, 7, 8, 9, 10]}\n",
        "parameters = {'alpha':[0.1, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 3, 3.2, 3.41, 3.42, 3.43, 3.44, 3.45, 3.46, 3.57, 3.48, 3.49, 3.5, 3.51, 3.52, 3.53, 3.54, 3.55, 3.56, 3.57, 3.58, 3.59, 5, 10, 15, 100, 500, 1000]}\n",
        "lr_best_params, lr_best_score, lr_test_score, lr_coef, lr_intercept = regression_optimizer(Ridge(), parameters, X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"Polynomial, Ridge\")\n",
        "#parameters = {'alpha': [50.0, 100, 200, 300, 400, 450, 460, 470, 480, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 499.5, 499.8, 499.9, 499.95, 500, 500.05, 500.1, 500.2, 500.5, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 600, 800, 900, 1000, 1500, 2000, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3650, 3700, 3730, 3740, 3750, 3760, 3770, 3800]}\n",
        "#parameters = {'alpha': [10,11,12,13,14,15,16,17,18,19,20,21,21.5,21.6,21.7,21.75,21.76,21.77,21.78,21.79,21.8,21.81,21.82,21.83,21.84,21.85,21.9,22,22.1,22.2,22.3,22.4,22.5,22.6,22.7,22.8,22.9,23,24,25,26,27,28,29]}\n",
        "parameters = {'alpha': [0.1, 1, 3, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5, 6, 7, 8, 9, 10, 19.1, 19.5, 19.7, 19.8, 19.9, 20, 20.1, 20.15, 20.2, 20.21, 20.22, 20.23, 20.24, 20.25, 20.26, 20.27, 20.28, 20.29, 20.3, 20.4, 20.5, 20.7, 21, 50, 100, 500, 1000]}\n",
        "pr_best_params, pr_best_score, pr_test_score, pr_coef, lr_intercept = regression_optimizer(Ridge(), parameters, poly_features, y_train, X_test_features, y_test)\n",
        "\n",
        "print(\"Linear, Lasso\")\n",
        "parameters = {'alpha':[0, 0.00001, 0.0001, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.03, 0.05, 0.07, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 1.0, 1.05, 1.1, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.3, 1.35, 1.38, 1.4, 1.41, 1.42, 1.43, 1.44, 1.45, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16.1, 16.2, 16.3, 16.4, 16.5, 16.6, 16.7, 16.8, 16.9, 17, 17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8, 17.9, 18, 19, 20, 25, 30, 35, 40, 45, 50, 100, 500, 1000]}\n",
        "ll_best_params, ll_best_score, ll_test_score, ll_coef, lr_intercept = regression_optimizer(Lasso(), parameters, X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"Polynomial, Lasso\")\n",
        "#parameters = {'alpha':[10, 50, 60, 70, 80, 90, 100, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 120, 130, 140, 150, 200]}\n",
        "parameters = {'alpha':[0.1, 0.5, 0.6, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.8, 0.9, 1, 1.5, 2, 3, 3.5, 3.51, 3.52, 3.53, 3.54, 3.55, 3.56, 3.57, 3.58, 3.59, 3.6, 3.61, 3.62, 3.63, 3.64, 3.65, 3.66, 3.67, 3.68, 3.69, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7,8,9,9.5, 9.6, 9.7, 9.8, 9.9, 10, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 11,11.5,12,12.1,12.2,12.3,12.4,12.5,12.55,12.56,12.57,12.58,12.59,12.6,12.61,12.62,12.63,12.64,12.65,12.7,12.8,12.9,13,14, 50, 100, 500, 1000]}\n",
        "pl_best_params, pl_best_score, pl_test_score, pl_coef, lr_intercept = regression_optimizer(Lasso(), parameters, poly_features, y_train, X_test_features, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yxHsw_3tB_S",
        "outputId": "03512e87-9114-433e-b446-144b3da93a17"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear, Ridge\n",
            "{'alpha': 1.9}\n",
            "0.5807980525257721\n",
            "0.5482511088192508\n",
            "[[ 1259.6667396   4661.09785883 -1172.23897958]]\n",
            "[8678.90374458]\n",
            "Polynomial, Ridge\n",
            "{'alpha': 4.1}\n",
            "0.6433349181443198\n",
            "0.6296593194401521\n",
            "[[  794.76632205  5106.28768052 -1179.57817712   654.43474315\n",
            "    951.78921326  -349.08568294   962.25620219  -786.42458771\n",
            "   -454.63773304]]\n",
            "[7415.51573209]\n",
            "Linear, Lasso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+09, tolerance: 1.153e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+09, tolerance: 1.074e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+09, tolerance: 1.102e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+09, tolerance: 1.117e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+09, tolerance: 1.140e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 16.8}\n",
            "0.5807854117907906\n",
            "0.5506190956519172\n",
            "[[ 1208.68295496  4450.12891929 -1152.14809516]]\n",
            "[8675.6912962]\n",
            "Polynomial, Lasso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.977e+07, tolerance: 1.102e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+07, tolerance: 1.102e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 6.7}\n",
            "0.6430909322749694\n",
            "0.6302999404979368\n",
            "[[  791.02439483  5053.28954844 -1176.17757987   651.35352657\n",
            "    943.89114532  -346.21800846   939.8809015   -765.99325791\n",
            "   -456.01162777]]\n",
            "[7444.45576415]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "random_features = poly.fit_transform([[2,3,4]]) # x1 x2 x3 x1^2 x1x2 x1x3 x2^2 x2x3 x3^2\n",
        "print(random_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuj62c4h1hBa",
        "outputId": "26d72dd1-e8f2-4afb-9d36-7f31301fb1d9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.  3.  4.  4.  6.  8.  9. 12. 16.]]\n"
          ]
        }
      ]
    }
  ]
}